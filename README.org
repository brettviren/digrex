#+title: In which I play with protocol buffers and zeromq

The latest prototyping is in [[./dexnet/]].

* The Toy

** Goal

I want

- to test the I/O performance of the possible nodes in the DUNE FD
  backend.

- this test to cover the non-algorithm parts but which may cover parts
  that involve accumulating and distributing the data.

- to follow best practices for ZMQ and protobuf.

- the overall distributed application to be organized as a graph of
  nodes exchanging messages on edges.

- to have a single node executable which may implement all possible
  node roles as determined by a coherent configuration set.

- a way to handle distributed deployment and execution of the nodes.

- to investigate global behavior in particular network responses to
  new nodes being added or falling out and to perform some kind of
  dynamic graph migration to a new topology.

- to consider dynamic discovery instead of configured endpoints.

See ~TODO~ below for a more concrete list.


** Model

- A "channel group" represents some fixed sized set of collection
  channels.  Eg, 48, 240, 480, 960.  This size is to be explored.

- A loop produces fake trigger primitives across its group consistent
  with Ar39 rate.

- A criteria is applied in that loop to bundle the recently produced
  primitives so they may be sent out a socket.

- All bundles from a "channel group" are collected by one front end
  computer (FEC) are bundled and sent out a socket.

- A number of FECs feed one trigger candidate processor which sends
  out a TC to a socket.

- A number of TCPs send to a MTL

** Implementaiton

There are a number of options to consider

 - multiplicity at each level

 - topology of network in terms of graph connectivity and socket types

Testing requires deploying and starting the test processes.  In order
to reduce complexity at this level *a single executable can fulfill
every role*.  Behavior is controlled by command line arguments.

Because the performance is not expected to be ample, a Python
prototype is skipped and a C++ implementation is used from the start.

** Usage

The distributed part isn't there yet so one has to start each node by
hand on ~localhost~.

#+BEGIN_EXAMPLE
  $ mkdir cfg
  $ jsonnet -m cfg dfdnode.jsonnet
  $ dfdnode cfg/PASource_source42.json &
  $ dfdnode cfg/PASink_sink.json &
#+END_EXAMPLE

Best to start nodes in different terminals as they spew to stdout.




